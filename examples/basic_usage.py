#!/usr/bin/env python3
"""
æ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç»“åˆäº† LangGraph å’Œ DSPy çš„æ™ºèƒ½è¿ç»´ç³»ç»Ÿï¼š
1. åˆå§‹åŒ–æ™ºèƒ½ä½“
2. å¤„ç†ç›‘æ§å‘Šè­¦
3. æ‰§è¡Œè‡ªåŠ¨åŒ–è¿ç»´
4. ç”Ÿæˆè¿ç»´æŠ¥å‘Š
"""

import asyncio
import os
import sys
from datetime import datetime
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.langgraph_workflow.ops_workflow import OpsWorkflow
from src.dspy_modules.alert_analyzer import AlertInfo
from src.langgraph_workflow.state_manager import StateManager


async def main():
    """ä¸»è¦æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ æ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“æ¼”ç¤ºå¼€å§‹")
    print("=" * 50)
    
    # 1. åˆå§‹åŒ–æ™ºèƒ½è¿ç»´å·¥ä½œæµ
    print("\nğŸ“‹ 1. åˆå§‹åŒ–æ™ºèƒ½è¿ç»´å·¥ä½œæµ")
    ops_workflow = OpsWorkflow()
    
    # éªŒè¯å·¥ä½œæµé…ç½®
    validation_errors = ops_workflow.validate_workflow()
    if validation_errors:
        print(f"âŒ å·¥ä½œæµéªŒè¯å¤±è´¥: {validation_errors}")
        return
    
    print("âœ… å·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
    
    # ç¼–è¯‘å·¥ä½œæµå›¾
    compiled_graph = ops_workflow.compile()
    print("âœ… å·¥ä½œæµç¼–è¯‘å®Œæˆ")
    
    # 2. åˆ›å»ºæ¨¡æ‹Ÿå‘Šè­¦
    print("\nğŸš¨ 2. åˆ›å»ºæ¨¡æ‹Ÿå‘Šè­¦")
    alert_info = AlertInfo(
        alert_id="alert_20240101_120000",
        timestamp=datetime.now().isoformat(),
        severity="high",
        source="monitoring_system",
        message="CPU usage exceeds 80% threshold on web-server-01",
        metrics={
            "cpu_usage": 0.85,
            "memory_usage": 0.72,
            "disk_usage": 0.45
        },
        tags=["cpu", "performance", "web-server-01"]
    )
    
    print(f"å‘Šè­¦ID: {alert_info.alert_id}")
    print(f"ä¸¥é‡ç¨‹åº¦: {alert_info.severity}")
    print(f"å‘Šè­¦æ¶ˆæ¯: {alert_info.message}")
    
    # 3. åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
    print("\nğŸ”„ 3. åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€")
    state_manager = StateManager()
    initial_state = state_manager.initialize_state("demo_workflow_001")
    
    # å°†å‘Šè­¦æ·»åŠ åˆ°çŠ¶æ€ä¸­
    initial_state = state_manager.update_state(initial_state, {
        "current_alert": alert_info,
        "system_metrics": {
            "cpu_usage": 0.85,
            "memory_usage": 0.72,
            "disk_usage": 0.45,
            "network_latency": 120
        },
        "system_context": {
            "environment": "production",
            "region": "us-east-1",
            "cluster": "web-cluster-01"
        }
    })
    
    print(f"å·¥ä½œæµID: {initial_state['workflow_id']}")
    print(f"åˆå§‹é˜¶æ®µ: {initial_state['workflow_stage']}")
    
    # 4. è¿è¡Œæ™ºèƒ½è¿ç»´å·¥ä½œæµ
    print("\nğŸ”„ 4. è¿è¡Œæ™ºèƒ½è¿ç»´å·¥ä½œæµ")
    print("å¼€å§‹è‡ªåŠ¨åŒ–è¿ç»´æµç¨‹...")
    
    try:
        # ä½¿ç”¨æµå¼è¿è¡Œä»¥è§‚å¯Ÿè¿›åº¦
        async for step in ops_workflow.stream_run(initial_state, max_iterations=50):
            for node_name, node_output in step.items():
                print(f"ğŸ“ èŠ‚ç‚¹ '{node_name}' æ‰§è¡Œå®Œæˆ")
                print(f"   é˜¶æ®µ: {node_output.get('workflow_stage', 'N/A')}")
                print(f"   çŠ¶æ€: {node_output.get('workflow_status', 'N/A')}")
                
                # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
                if node_output.get('alert_analysis'):
                    analysis = node_output['alert_analysis']
                    print(f"   ğŸ“Š å‘Šè­¦åˆ†æ: ä¼˜å…ˆçº§={analysis.priority}, åˆ†ç±»={analysis.category}")
                
                if node_output.get('diagnostic_result'):
                    diagnosis = node_output['diagnostic_result']
                    print(f"   ğŸ” è¯Šæ–­ç»“æœ: {diagnosis.root_cause}")
                
                if node_output.get('action_plan'):
                    plan = node_output['action_plan']
                    print(f"   ğŸ“‹ è¡ŒåŠ¨è®¡åˆ’: {len(plan.steps)} ä¸ªæ­¥éª¤")
                
                if node_output.get('execution_result'):
                    execution = node_output['execution_result']
                    print(f"   âš¡ æ‰§è¡Œç»“æœ: {execution.status}")
                
                if node_output.get('incident_report'):
                    report = node_output['incident_report']
                    print(f"   ğŸ“„ äº‹ä»¶æŠ¥å‘Š: {report.title}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                if node_output.get('errors'):
                    print(f"   âš ï¸  é”™è¯¯: {len(node_output['errors'])} ä¸ª")
                
                print()
        
        print("âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
        return
    
    # 5. è·å–å·¥ä½œæµæŒ‡æ ‡
    print("\nğŸ“Š 5. å·¥ä½œæµæ‰§è¡ŒæŒ‡æ ‡")
    metrics = ops_workflow.get_workflow_metrics("demo_workflow_001")
    
    print(f"æ‰§è¡Œæ—¶é—´: {metrics.get('execution_time_seconds', 0):.2f} ç§’")
    print(f"æœ€ç»ˆçŠ¶æ€: {metrics.get('status', 'N/A')}")
    print(f"æˆåŠŸç‡: {metrics.get('success_rate', 0):.2%}")
    print(f"é‡è¯•æ¬¡æ•°: {metrics.get('retry_count', 0)}")
    print(f"é”™è¯¯æ€»æ•°: {metrics.get('total_errors', 0)}")
    
    # 6. è·å–çŠ¶æ€å¿«ç…§
    print("\nğŸ’¾ 6. çŠ¶æ€å¿«ç…§")
    snapshot = ops_workflow.get_state_snapshot("demo_workflow_001")
    if snapshot:
        print(f"å·¥ä½œæµID: {snapshot.get('workflow_id')}")
        print(f"å½“å‰é˜¶æ®µ: {snapshot.get('stage')}")
        print(f"å¼€å§‹æ—¶é—´: {snapshot.get('start_time')}")
        print(f"æœ€åæ›´æ–°: {snapshot.get('last_update')}")
    
    # 7. æ˜¾ç¤ºå·¥ä½œæµå®šä¹‰
    print("\nğŸ“‹ 7. å·¥ä½œæµå®šä¹‰")
    definition = ops_workflow.get_workflow_definition()
    print(f"åç§°: {definition['name']}")
    print(f"ç‰ˆæœ¬: {definition['version']}")
    print(f"èŠ‚ç‚¹æ•°é‡: {len(definition['nodes'])}")
    print(f"é˜¶æ®µ: {', '.join(definition['stages'])}")
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“æ¼”ç¤ºå®Œæˆ")


def demo_individual_components():
    """æ¼”ç¤ºå„ä¸ªç»„ä»¶çš„ç‹¬ç«‹ä½¿ç”¨"""
    print("\nğŸ”§ ç»„ä»¶ç‹¬ç«‹ä½¿ç”¨æ¼”ç¤º")
    print("=" * 30)
    
    # DSPy æ¨¡å—æ¼”ç¤º
    from src.dspy_modules.alert_analyzer import AlertAnalyzer
    from src.dspy_modules.diagnostic_agent import DiagnosticAgent, DiagnosticContext
    from src.dspy_modules.action_planner import ActionPlanner
    from src.dspy_modules.report_generator import ReportGenerator
    
    print("\nğŸ“Š DSPy å‘Šè­¦åˆ†æå™¨æ¼”ç¤º")
    alert_analyzer = AlertAnalyzer()
    
    # åˆ›å»ºç¤ºä¾‹å‘Šè­¦
    alert = AlertInfo(
        alert_id="demo_alert_001",
        timestamp=datetime.now().isoformat(),
        severity="high",
        source="cpu_monitor",
        message="High CPU usage detected on server-01",
        metrics={"cpu_usage": 0.90},
        tags=["cpu", "server-01"]
    )
    
    try:
        # æ³¨æ„: è¿™é‡Œéœ€è¦å®é™…çš„ DSPy æ¨¡å‹é…ç½®æ‰èƒ½è¿è¡Œ
        # analysis = alert_analyzer.forward(alert)
        # print(f"åˆ†æç»“æœ: {analysis}")
        print("ğŸ’¡ DSPy æ¨¡å—éœ€è¦é…ç½®è¯­è¨€æ¨¡å‹åæ‰èƒ½è¿è¡Œ")
    except Exception as e:
        print(f"âš ï¸  DSPy æ¨¡å—æ¼”ç¤ºè·³è¿‡: {str(e)}")
    
    print("\nğŸ—ï¸  LangGraph çŠ¶æ€ç®¡ç†æ¼”ç¤º")
    state_manager = StateManager()
    
    # åˆ›å»ºåˆå§‹çŠ¶æ€
    state = state_manager.initialize_state("demo_state_001")
    print(f"åˆå§‹çŠ¶æ€: {state_manager.get_state_summary(state)}")
    
    # æ›´æ–°çŠ¶æ€
    updated_state = state_manager.update_state(state, {
        "current_alert": alert,
        "workflow_stage": "alerting"
    })
    print(f"æ›´æ–°åçŠ¶æ€: {state_manager.get_state_summary(updated_state)}")
    
    # éªŒè¯çŠ¶æ€
    validation_errors = state_manager.validate_state(updated_state)
    if validation_errors:
        print(f"çŠ¶æ€éªŒè¯é”™è¯¯: {validation_errors}")
    else:
        print("âœ… çŠ¶æ€éªŒè¯é€šè¿‡")


if __name__ == "__main__":
    # è¿è¡Œä¸»æ¼”ç¤º
    asyncio.run(main())
    
    # è¿è¡Œç»„ä»¶æ¼”ç¤º
    demo_individual_components()
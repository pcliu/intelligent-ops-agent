#!/usr/bin/env python3
"""
DeepSeek LLM é…ç½®å’Œæµ‹è¯•ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•é…ç½®å’Œä½¿ç”¨ DeepSeek ä½œä¸ºæ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“çš„è¯­è¨€æ¨¡å‹
"""

import asyncio
import os
import sys
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.utils.llm_config import (
    LLMConfig, 
    setup_deepseek_llm, 
    get_llm_config_from_env,
    validate_llm_config,
    test_llm_connection,
    DEEPSEEK_CONFIGS
)
from src.agents.intelligent_ops_agent import IntelligentOpsAgent, AgentConfig
from src.dspy_modules.alert_analyzer import AlertInfo


def setup_environment():
    """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
    # è®¾ç½®ç¯å¢ƒå˜é‡ (è¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™… API Key)
    test_api_key = os.getenv("DEEPSEEK_API_KEY")
    
    if not test_api_key:
        print("âš ï¸  è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        print("   æ–¹æ³•1: export DEEPSEEK_API_KEY='your-api-key'")
        print("   æ–¹æ³•2: åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ  DEEPSEEK_API_KEY")
        return False
    
    # è®¾ç½®å…¶ä»–ç¯å¢ƒå˜é‡
    os.environ.setdefault("LLM_PROVIDER", "deepseek")
    os.environ.setdefault("LLM_MODEL_NAME", "deepseek-chat")
    os.environ.setdefault("LLM_BASE_URL", "https://api.deepseek.com/v1")
    os.environ.setdefault("LLM_TEMPERATURE", "0.1")
    os.environ.setdefault("LLM_MAX_TOKENS", "2000")
    
    return True


def test_llm_configurations():
    """æµ‹è¯•ä¸åŒçš„ LLM é…ç½®"""
    print("\nğŸ”§ æµ‹è¯• LLM é…ç½®")
    print("=" * 40)
    
    # æµ‹è¯•1: ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    print("\n1. ä»ç¯å¢ƒå˜é‡è·å–é…ç½®")
    env_config = get_llm_config_from_env()
    print(f"   æä¾›å•†: {env_config.provider}")
    print(f"   æ¨¡å‹: {env_config.model_name}")
    print(f"   åŸºç¡€URL: {env_config.base_url}")
    print(f"   æ¸©åº¦: {env_config.temperature}")
    
    # éªŒè¯é…ç½®
    if validate_llm_config(env_config):
        print("   âœ… é…ç½®éªŒè¯é€šè¿‡")
    else:
        print("   âŒ é…ç½®éªŒè¯å¤±è´¥")
        return False
    
    # æµ‹è¯•2: ä½¿ç”¨é¢„è®¾é…ç½®
    print("\n2. ä½¿ç”¨é¢„è®¾ DeepSeek é…ç½®")
    deepseek_config = DEEPSEEK_CONFIGS["deepseek-chat"]
    deepseek_config.api_key = os.getenv("DEEPSEEK_API_KEY")
    
    print(f"   æ¨¡å‹: {deepseek_config.model_name}")
    print(f"   æœ€å¤§ä»¤ç‰Œ: {deepseek_config.max_tokens}")
    
    # æµ‹è¯•3: è‡ªå®šä¹‰é…ç½®
    print("\n3. è‡ªå®šä¹‰é…ç½®")
    custom_config = LLMConfig(
        provider="deepseek",
        model_name="deepseek-chat",
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com/v1",
        temperature=0.1,
        max_tokens=4000
    )
    
    print(f"   è‡ªå®šä¹‰æœ€å¤§ä»¤ç‰Œ: {custom_config.max_tokens}")
    
    return True


def test_basic_llm_functionality():
    """æµ‹è¯•åŸºç¡€ LLM åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•åŸºç¡€ LLM åŠŸèƒ½")
    print("=" * 40)
    
    try:
        # è·å–é…ç½®
        config = get_llm_config_from_env()
        config.api_key = os.getenv("DEEPSEEK_API_KEY")
        
        # è®¾ç½® LLM
        print("\n1. è®¾ç½® DeepSeek LLM")
        dspy_lm, langchain_llm = setup_deepseek_llm(config)
        print("   âœ… LLM è®¾ç½®å®Œæˆ")
        
        # æµ‹è¯• DSPy LLM
        print("\n2. æµ‹è¯• DSPy LLM")
        test_prompt = "è¯·ç”¨ä¸­æ–‡ç®€çŸ­å›ç­”ï¼šä»€ä¹ˆæ˜¯æ™ºèƒ½è¿ç»´ï¼Ÿ"
        response = dspy_lm(test_prompt)
        print(f"   é—®é¢˜: {test_prompt}")
        print(f"   å›ç­”: {response}")
        
        # æµ‹è¯• LangChain LLM
        print("\n3. æµ‹è¯• LangChain LLM")
        langchain_response = langchain_llm.invoke("è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯å‘Šè­¦åˆ†æ")
        print(f"   é—®é¢˜: è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯å‘Šè­¦åˆ†æ")
        print(f"   å›ç­”: {langchain_response.content}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ LLM åŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_dspy_modules_with_deepseek():
    """æµ‹è¯• DSPy æ¨¡å—ä¸ DeepSeek çš„é›†æˆ"""
    print("\nğŸ§  æµ‹è¯• DSPy æ¨¡å—ä¸ DeepSeek é›†æˆ")
    print("=" * 40)
    
    try:
        # è®¾ç½® LLM
        config = get_llm_config_from_env()
        config.api_key = os.getenv("DEEPSEEK_API_KEY")
        dspy_lm, _ = setup_deepseek_llm(config)
        
        # æµ‹è¯•å‘Šè­¦åˆ†æå™¨
        print("\n1. æµ‹è¯•å‘Šè­¦åˆ†æå™¨")
        from src.dspy_modules.alert_analyzer import AlertAnalyzer
        
        # åˆ›å»ºå‘Šè­¦åˆ†æå™¨å®ä¾‹
        alert_analyzer = AlertAnalyzer()
        
        test_alert = AlertInfo(
            alert_id="test_deepseek_001",
            timestamp="2024-01-01T12:00:00Z",
            severity="high",
            source="cpu_monitor",
            message="CPU ä½¿ç”¨ç‡è¶…è¿‡ 90% é˜ˆå€¼",
            metrics={"cpu_usage": 0.95},
            tags=["cpu", "performance"]
        )
        
        print(f"   å‘Šè­¦ä¿¡æ¯: {test_alert.message}")
        print("   ğŸ”„ æ­£åœ¨è°ƒç”¨ DeepSeek æ¨¡å‹è¿›è¡Œå‘Šè­¦åˆ†æ...")
        
        # å®é™…è°ƒç”¨ DSPy æ¨¡å—
        analysis_result = alert_analyzer.forward(
            alert_info=test_alert,
            historical_alerts=[]
        )
        
        print("   âœ… å‘Šè­¦åˆ†æå®Œæˆï¼")
        print(f"   - åˆ†ç±»: {analysis_result.category}")
        print(f"   - ä¼˜å…ˆçº§: {analysis_result.priority}")
        print(f"   - ç´§æ€¥ç¨‹åº¦: {analysis_result.urgency_score}")
        print(f"   - æ ¹å› æç¤º: {analysis_result.root_cause_hints[:100]}...")
        print(f"   - å»ºè®®æ“ä½œ: {analysis_result.recommended_actions[:100]}...")
        
        # æµ‹è¯•è¯Šæ–­æ™ºèƒ½ä½“
        print("\n2. æµ‹è¯•è¯Šæ–­æ™ºèƒ½ä½“")
        from src.dspy_modules.diagnostic_agent import DiagnosticAgent, DiagnosticContext
        
        diagnostic_agent = DiagnosticAgent()
        diagnostic_context = DiagnosticContext(
            alert_analysis=analysis_result,
            system_metrics={"cpu_usage": 0.95, "memory_usage": 0.65},
            log_entries=["2024-01-01 12:00:00 ERROR: High CPU usage detected"],
            historical_incidents=[],
            topology_info={"services": ["web", "api", "db"]}
        )
        
        print("   ğŸ”„ æ­£åœ¨è¿›è¡Œæ ¹å› è¯Šæ–­...")
        diagnostic_result = diagnostic_agent.forward(diagnostic_context)
        
        print("   âœ… è¯Šæ–­å®Œæˆï¼")
        print(f"   - æ ¹å› : {diagnostic_result.root_cause}")
        print(f"   - ç½®ä¿¡åº¦: {diagnostic_result.confidence_score}")
        print(f"   - å½±å“è¯„ä¼°: {diagnostic_result.impact_assessment}")
        print(f"   - æ¢å¤æ—¶é—´ä¼°è®¡: {diagnostic_result.recovery_time_estimate}")
        
        # æµ‹è¯•è¡ŒåŠ¨è§„åˆ’å™¨
        print("\n3. æµ‹è¯•è¡ŒåŠ¨è§„åˆ’å™¨")
        from src.dspy_modules.action_planner import ActionPlanner
        
        action_planner = ActionPlanner()
        
        print("   ğŸ”„ æ­£åœ¨ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’...")
        action_plan = action_planner.forward(
            diagnostic_result=diagnostic_result,
            system_context={"environment": "production", "cluster": "web-cluster"}
        )
        
        print("   âœ… è¡ŒåŠ¨è®¡åˆ’ç”Ÿæˆå®Œæˆï¼")
        print(f"   - è®¡åˆ’ID: {action_plan.plan_id}")
        print(f"   - ä¼˜å…ˆçº§: {action_plan.priority}")
        print(f"   - æ­¥éª¤æ•°é‡: {len(action_plan.steps)}")
        print(f"   - é¢„ä¼°æ—¶é—´: {action_plan.estimated_duration}åˆ†é’Ÿ")
        
        if action_plan.steps:
            print("   - ä¸»è¦æ­¥éª¤:")
            for i, step in enumerate(action_plan.steps[:3], 1):
                print(f"     {i}. {step.description}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ DSPy æ¨¡å—æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_intelligent_ops_agent_with_deepseek():
    """æµ‹è¯•æ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“ä¸ DeepSeek çš„é›†æˆ"""
    print("\nğŸ¤– æµ‹è¯•æ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“ä¸ DeepSeek é›†æˆ")
    print("=" * 40)
    
    try:
        # è®¾ç½® LLM
        config = get_llm_config_from_env()
        config.api_key = os.getenv("DEEPSEEK_API_KEY")
        setup_deepseek_llm(config)
        
        # æµ‹è¯•å®Œæ•´çš„å·¥ä½œæµ
        print("\n1. æµ‹è¯• LangGraph å·¥ä½œæµ")
        from src.langgraph_workflow.ops_workflow import OpsWorkflow
        from src.langgraph_workflow.state_manager import StateManager
        
        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = OpsWorkflow()
        state_manager = StateManager()
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = state_manager.initialize_state("deepseek_test_workflow")
        
        # æ·»åŠ æµ‹è¯•å‘Šè­¦
        test_alert = AlertInfo(
            alert_id="deepseek_workflow_test",
            timestamp="2024-01-01T12:00:00Z",
            severity="critical",
            source="deepseek_monitor",
            message="DeepSeek API å“åº”æ—¶é—´å¼‚å¸¸ï¼Œå½±å“ç”Ÿäº§ç¯å¢ƒ",
            metrics={
                "response_time": 8000,
                "success_rate": 0.75,
                "error_rate": 0.25,
                "cpu_usage": 0.90
            },
            tags=["api", "performance", "deepseek", "critical"]
        )
        
        # æ›´æ–°çŠ¶æ€ï¼Œæ·»åŠ å‘Šè­¦
        initial_state = state_manager.update_state(initial_state, {
            "current_alert": test_alert
        })
        
        print(f"   å‘Šè­¦: {test_alert.message}")
        print("   ğŸ”„ æ­£åœ¨è¿è¡Œå®Œæ•´çš„æ™ºèƒ½è¿ç»´å·¥ä½œæµ...")
        
        # è¿è¡Œå·¥ä½œæµ
        step_count = 0
        results = {}
        
        async for step in workflow.stream_run(initial_state, max_iterations=10):
            step_count += 1
            step_name = list(step.keys())[0] if step else "unknown"
            print(f"   ğŸ“Š æ­¥éª¤ {step_count}: {step_name}")
            
            # ä¿å­˜ç»“æœ
            if step:
                results.update(step)
            
            # é™åˆ¶æ­¥éª¤æ•°é‡
            if step_count >= 8:
                break
        
        print("   âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
        
        # æ˜¾ç¤ºå…³é”®ç»“æœ
        final_state = list(results.values())[-1] if results else initial_state
        
        if final_state.get("alert_analysis"):
            analysis = final_state["alert_analysis"]
            print(f"   - å‘Šè­¦åˆ†æ: {analysis.category} (ä¼˜å…ˆçº§: {analysis.priority})")
        
        if final_state.get("diagnostic_result"):
            diagnosis = final_state["diagnostic_result"]
            print(f"   - è¯Šæ–­ç»“æœ: {diagnosis.root_cause}")
            print(f"   - ç½®ä¿¡åº¦: {diagnosis.confidence_score}")
        
        if final_state.get("action_plan"):
            plan = final_state["action_plan"]
            print(f"   - è¡ŒåŠ¨è®¡åˆ’: {len(plan.steps)}ä¸ªæ­¥éª¤")
            print(f"   - é¢„ä¼°æ—¶é—´: {plan.estimated_duration}åˆ†é’Ÿ")
        
        if final_state.get("execution_result"):
            exec_result = final_state["execution_result"]
            print(f"   - æ‰§è¡Œç»“æœ: {exec_result.status}")
        
        if final_state.get("incident_report"):
            report = final_state["incident_report"]
            print(f"   - äº‹ä»¶æŠ¥å‘Š: {report.incident_id}")
        
        # æµ‹è¯•é«˜çº§æ™ºèƒ½ä½“åŠŸèƒ½
        print("\n2. æµ‹è¯•é«˜çº§æ™ºèƒ½ä½“åŠŸèƒ½")
        agent_config = AgentConfig(
            agent_id="deepseek_advanced_agent",
            agent_type="general",
            specialization="deepseek_powered",
            enable_learning=True,
            enable_reporting=True,
            auto_execution=False
        )
        
        agent = IntelligentOpsAgent(agent_config)
        print(f"   âœ… é«˜çº§æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ: {agent_config.agent_id}")
        
        # æµ‹è¯•å‘Šè­¦å¤„ç†
        alert_dict = {
            "alert_id": "deepseek_advanced_test",
            "timestamp": "2024-01-01T12:00:00Z",
            "severity": "high",
            "source": "advanced_monitor",
            "message": "å†…å­˜ä½¿ç”¨ç‡æŒç»­ä¸Šå‡ï¼Œå¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼",
            "metrics": {
                "memory_usage": 0.92,
                "memory_growth_rate": 0.05,
                "gc_frequency": 500
            },
            "tags": ["memory", "leak", "performance"]
        }
        
        print(f"   å‘Šè­¦: {alert_dict['message']}")
        print("   ğŸ”„ æ­£åœ¨å¤„ç†å‘Šè­¦...")
        
        # ä½¿ç”¨æ™ºèƒ½ä½“å¤„ç†å‘Šè­¦
        result = await agent.process_alert(alert_dict)
        print(f"   âœ… å‘Šè­¦å¤„ç†: {result['status']}")
        
        # è·å–æ€§èƒ½æŒ‡æ ‡
        metrics = agent.get_performance_metrics()
        print(f"   ğŸ“Š å¤„ç†äº‹ä»¶æ•°: {metrics['incidents_processed']}")
        print(f"   ğŸ“Š æˆåŠŸç‡: {metrics['success_rate']:.1%}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def demonstrate_deepseek_features():
    """æ¼”ç¤º DeepSeek çš„ç‰¹æ€§"""
    print("\nâ­ DeepSeek ç‰¹æ€§æ¼”ç¤º")
    print("=" * 40)
    
    print("\nğŸ”¹ DeepSeek ä¼˜åŠ¿:")
    print("   â€¢ é«˜æ€§ä»·æ¯”ï¼šAPI è°ƒç”¨æˆæœ¬ä½")
    print("   â€¢ ä¸­æ–‡ä¼˜åŒ–ï¼šå¯¹ä¸­æ–‡ç†è§£å’Œç”Ÿæˆæ•ˆæœå¥½")
    print("   â€¢ ä»£ç èƒ½åŠ›ï¼šDeepSeek-Coder åœ¨ä»£ç ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜ç§€")
    print("   â€¢ å¼€æºé€æ˜ï¼šæ¨¡å‹æ¶æ„å’Œè®­ç»ƒæ–¹æ³•å…¬å¼€")
    print("   â€¢ API å…¼å®¹ï¼šæ”¯æŒ OpenAI æ ¼å¼çš„ API è°ƒç”¨")
    
    print("\nğŸ”¹ é€‚ç”¨åœºæ™¯:")
    print("   â€¢ è¿ç»´æ—¥å¿—åˆ†æï¼ˆä¸­æ–‡æ—¥å¿—å‹å¥½ï¼‰")
    print("   â€¢ æ•…éšœè¯Šæ–­æŠ¥å‘Šç”Ÿæˆ")
    print("   â€¢ è‡ªåŠ¨åŒ–è„šæœ¬ç”Ÿæˆ")
    print("   â€¢ è¿ç»´çŸ¥è¯†é—®ç­”")
    print("   â€¢ æˆæœ¬æ•æ„Ÿçš„å¤§è§„æ¨¡éƒ¨ç½²")
    
    print("\nğŸ”¹ é…ç½®å»ºè®®:")
    print("   â€¢ é€šç”¨ä»»åŠ¡ï¼šä½¿ç”¨ deepseek-chat")
    print("   â€¢ ä»£ç ç”Ÿæˆï¼šä½¿ç”¨ deepseek-coder")
    print("   â€¢ æ¸©åº¦è®¾ç½®ï¼š0.1-0.3 (è¿ç»´ä»»åŠ¡éœ€è¦å‡†ç¡®æ€§)")
    print("   â€¢ ä»¤ç‰Œæ•°é‡ï¼š2000-4000 (æ ¹æ®ä»»åŠ¡å¤æ‚åº¦)")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ DeepSeek LLM é…ç½®å’Œæµ‹è¯•")
    print("=" * 50)
    
    # 1. ç¯å¢ƒè®¾ç½®
    if not setup_environment():
        print("\nâŒ ç¯å¢ƒè®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key é…ç½®")
        return
    
    # 2. é…ç½®æµ‹è¯•
    if not test_llm_configurations():
        print("\nâŒ é…ç½®æµ‹è¯•å¤±è´¥")
        return
    
    # 3. è¿æ¥æµ‹è¯•
    if not test_llm_connection():
        print("\nâŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’Œ API Key")
        return
    
    # 4. åŸºç¡€åŠŸèƒ½æµ‹è¯•
    if test_basic_llm_functionality():
        print("\nâœ… åŸºç¡€åŠŸèƒ½æµ‹è¯•æˆåŠŸ")
    
    # 5. DSPy æ¨¡å—æµ‹è¯•
    if test_dspy_modules_with_deepseek():
        print("\nâœ… DSPy æ¨¡å—æµ‹è¯•æˆåŠŸ")
    
    # 6. æ™ºèƒ½ä½“æµ‹è¯•
    if await test_intelligent_ops_agent_with_deepseek():
        print("\nâœ… æ™ºèƒ½ä½“æµ‹è¯•æˆåŠŸ")
    
    # 7. ç‰¹æ€§æ¼”ç¤º
    demonstrate_deepseek_features()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ DeepSeek LLM é…ç½®å’Œæµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ æ¥ä¸‹æ¥çš„æ­¥éª¤:")
    print("   1. è®¾ç½®æ‚¨çš„ DEEPSEEK_API_KEY")
    print("   2. è¿è¡Œå®Œæ•´çš„æ™ºèƒ½è¿ç»´ç¤ºä¾‹")
    print("   3. æ ¹æ®éœ€è¦è°ƒæ•´æ¨¡å‹å‚æ•°")
    print("   4. åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²")


if __name__ == "__main__":
    asyncio.run(main())
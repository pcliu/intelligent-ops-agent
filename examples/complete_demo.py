#!/usr/bin/env python3
"""
æ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“å®Œæ•´æ¼”ç¤º

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“è¿›è¡Œå®Œæ•´çš„è¿ç»´æµç¨‹ï¼š
1. åˆ›å»ºå’Œé…ç½®æ™ºèƒ½ä½“
2. å¤„ç†çœŸå®è¿ç»´åœºæ™¯
3. å¤šæ™ºèƒ½ä½“åä½œ
4. å­¦ä¹ å’Œä¼˜åŒ–
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.agents.intelligent_ops_agent import IntelligentOpsAgent, AgentConfig, AgentManager
from src.dspy_modules.alert_analyzer import AlertInfo


class OpsScenarioGenerator:
    """è¿ç»´åœºæ™¯ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_cpu_spike_scenario() -> Dict[str, Any]:
        """ç”ŸæˆCPUå³°å€¼åœºæ™¯"""
        return {
            "alert": {
                "alert_id": f"cpu_spike_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "timestamp": datetime.now().isoformat(),
                "severity": "high",
                "source": "system_monitor",
                "message": "CPU usage exceeded 90% threshold on production server",
                "metrics": {
                    "cpu_usage": 0.95,
                    "memory_usage": 0.78,
                    "disk_io": 0.82,
                    "network_io": 0.65
                },
                "tags": ["cpu", "performance", "production", "server-web-01"]
            },
            "context": {
                "environment": "production",
                "affected_services": ["web_service", "api_service"],
                "user_impact": "Response time increased by 200%",
                "business_impact": "Customer checkout process affected"
            }
        }
    
    @staticmethod
    def generate_memory_leak_scenario() -> Dict[str, Any]:
        """ç”Ÿæˆå†…å­˜æ³„æ¼åœºæ™¯"""
        return {
            "alert": {
                "alert_id": f"memory_leak_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "timestamp": datetime.now().isoformat(),
                "severity": "critical",
                "source": "application_monitor",
                "message": "Memory usage continuously increasing, potential memory leak detected",
                "metrics": {
                    "memory_usage": 0.92,
                    "memory_growth_rate": 0.05,  # 5% per hour
                    "gc_frequency": 500,  # per minute
                    "heap_size": 8000000000  # 8GB
                },
                "tags": ["memory", "leak", "application", "java"]
            },
            "context": {
                "environment": "production",
                "affected_services": ["order_service", "inventory_service"],
                "user_impact": "Service crashes every 2 hours",
                "business_impact": "Order processing failures"
            }
        }
    
    @staticmethod
    def generate_network_outage_scenario() -> Dict[str, Any]:
        """ç”Ÿæˆç½‘ç»œä¸­æ–­åœºæ™¯"""
        return {
            "alert": {
                "alert_id": f"network_outage_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "timestamp": datetime.now().isoformat(),
                "severity": "critical",
                "source": "network_monitor",
                "message": "Network connectivity lost to external services",
                "metrics": {
                    "packet_loss": 0.80,
                    "latency": 5000,  # 5 seconds
                    "bandwidth_utilization": 0.05,
                    "connection_success_rate": 0.15
                },
                "tags": ["network", "outage", "external", "connectivity"]
            },
            "context": {
                "environment": "production",
                "affected_services": ["payment_service", "notification_service"],
                "user_impact": "Cannot complete transactions",
                "business_impact": "Revenue loss estimated at $10,000/hour"
            }
        }
    
    @staticmethod
    def generate_security_incident_scenario() -> Dict[str, Any]:
        """ç”Ÿæˆå®‰å…¨äº‹ä»¶åœºæ™¯"""
        return {
            "alert": {
                "alert_id": f"security_incident_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "timestamp": datetime.now().isoformat(),
                "severity": "critical",
                "source": "security_monitor",
                "message": "Suspicious login attempts detected from multiple IP addresses",
                "metrics": {
                    "failed_login_attempts": 150,
                    "suspicious_ips": 25,
                    "brute_force_score": 0.9,
                    "account_lockouts": 8
                },
                "tags": ["security", "authentication", "brute_force", "attack"]
            },
            "context": {
                "environment": "production",
                "affected_services": ["auth_service", "user_service"],
                "user_impact": "Legitimate users unable to login",
                "business_impact": "Potential data breach risk"
            }
        }


async def demo_single_agent_ops():
    """æ¼”ç¤ºå•ä¸ªæ™ºèƒ½ä½“è¿ç»´æµç¨‹"""
    print("\nğŸ¤– å•ä¸ªæ™ºèƒ½ä½“è¿ç»´æµç¨‹æ¼”ç¤º")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ™ºèƒ½ä½“
    print("\nğŸ“‹ 1. åˆ›å»ºæ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“")
    config = AgentConfig(
        agent_id="ops_agent_001",
        agent_type="general",
        specialization="system_performance",
        max_retries=3,
        timeout=300,
        enable_learning=True,
        enable_reporting=True,
        auto_execution=False  # æ¼”ç¤ºæ¨¡å¼ï¼Œç¦ç”¨è‡ªåŠ¨æ‰§è¡Œ
    )
    
    agent = IntelligentOpsAgent(config)
    print(f"âœ… æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ: {config.agent_id}")
    print(f"   ç±»å‹: {config.agent_type}")
    print(f"   ä¸“ä¸šåŒ–: {config.specialization}")
    
    # 2. å¤„ç† CPU å³°å€¼åœºæ™¯
    print("\nğŸš¨ 2. å¤„ç† CPU å³°å€¼å‘Šè­¦")
    cpu_scenario = OpsScenarioGenerator.generate_cpu_spike_scenario()
    
    print(f"å‘Šè­¦ä¿¡æ¯: {cpu_scenario['alert']['message']}")
    print(f"CPUä½¿ç”¨ç‡: {cpu_scenario['alert']['metrics']['cpu_usage']:.1%}")
    print(f"ä¸šåŠ¡å½±å“: {cpu_scenario['context']['business_impact']}")
    
    # å¤„ç†å‘Šè­¦
    result = await agent.process_alert(cpu_scenario['alert'])
    print(f"\nğŸ“Š å¤„ç†ç»“æœ: {result['status']}")
    
    if result['status'] == 'success':
        print("âœ… å‘Šè­¦å¤„ç†æˆåŠŸ")
        if result.get('alert_analysis'):
            analysis = result['alert_analysis']
            print(f"   ä¼˜å…ˆçº§: {analysis.priority}")
            print(f"   åˆ†ç±»: {analysis.category}")
            print(f"   ç´§æ€¥ç¨‹åº¦: {analysis.urgency_score:.2f}")
        
        if result.get('diagnostic_result'):
            diagnosis = result['diagnostic_result']
            print(f"   æ ¹å› : {diagnosis.root_cause}")
            print(f"   ç½®ä¿¡åº¦: {diagnosis.confidence_score:.2f}")
        
        if result.get('action_plan'):
            plan = result['action_plan']
            print(f"   è®¡åˆ’æ­¥éª¤: {len(plan.steps)}ä¸ª")
            print(f"   é¢„ä¼°æ—¶é—´: {plan.estimated_duration}åˆ†é’Ÿ")
    
    # 3. è·å–æ™ºèƒ½ä½“çŠ¶æ€
    print("\nğŸ“Š 3. æ™ºèƒ½ä½“çŠ¶æ€")
    status = agent.get_agent_status()
    print(f"çŠ¶æ€: {status['current_state']}")
    print(f"å·¥ä½œæµçŠ¶æ€: {status['workflow_status']}")
    print(f"å¤„ç†äº‹ä»¶æ•°: {status['incident_count']}")
    
    # 4. è·å–æ€§èƒ½æŒ‡æ ‡
    print("\nğŸ“ˆ 4. æ€§èƒ½æŒ‡æ ‡")
    metrics = agent.get_performance_metrics()
    print(f"å¤„ç†äº‹ä»¶æ•°: {metrics['incidents_processed']}")
    print(f"å¹³å‡è§£å†³æ—¶é—´: {metrics['average_resolution_time']:.1f}ç§’")
    print(f"æˆåŠŸç‡: {metrics['success_rate']:.1%}")
    
    return agent


async def demo_multi_agent_collaboration():
    """æ¼”ç¤ºå¤šæ™ºèƒ½ä½“åä½œ"""
    print("\nğŸ¤ å¤šæ™ºèƒ½ä½“åä½œæ¼”ç¤º")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ™ºèƒ½ä½“ç®¡ç†å™¨
    print("\nğŸ“‹ 1. åˆ›å»ºæ™ºèƒ½ä½“ç®¡ç†å™¨")
    manager = AgentManager()
    
    # 2. åˆ›å»ºä¸“ä¸šåŒ–æ™ºèƒ½ä½“
    print("\nğŸ¤– 2. åˆ›å»ºä¸“ä¸šåŒ–æ™ºèƒ½ä½“")
    agents_config = [
        AgentConfig(
            agent_id="network_specialist",
            agent_type="network",
            specialization="network_diagnostics",
            enable_learning=True,
            enable_reporting=True
        ),
        AgentConfig(
            agent_id="security_specialist",
            agent_type="security",
            specialization="security_response",
            enable_learning=True,
            enable_reporting=True
        ),
        AgentConfig(
            agent_id="performance_specialist",
            agent_type="performance",
            specialization="performance_optimization",
            enable_learning=True,
            enable_reporting=True
        )
    ]
    
    agents = {}
    for config in agents_config:
        agent = manager.create_agent(config)
        agents[config.agent_id] = agent
        print(f"âœ… åˆ›å»ºæ™ºèƒ½ä½“: {config.agent_id} ({config.specialization})")
    
    # 3. å¤„ç†å¤æ‚åœºæ™¯
    print("\nğŸš¨ 3. å¤„ç†å¤æ‚å®‰å…¨äº‹ä»¶")
    security_scenario = OpsScenarioGenerator.generate_security_incident_scenario()
    
    print(f"äº‹ä»¶: {security_scenario['alert']['message']}")
    print(f"å¤±è´¥ç™»å½•å°è¯•: {security_scenario['alert']['metrics']['failed_login_attempts']}")
    print(f"å¯ç–‘IPæ•°é‡: {security_scenario['alert']['metrics']['suspicious_ips']}")
    
    # å®‰å…¨æ™ºèƒ½ä½“å¤„ç†
    security_agent = agents['security_specialist']
    security_result = await security_agent.process_alert(security_scenario['alert'])
    
    print(f"\nğŸ”’ å®‰å…¨æ™ºèƒ½ä½“å¤„ç†ç»“æœ: {security_result['status']}")
    
    # 4. ç½‘ç»œæ•…éšœåœºæ™¯
    print("\nğŸŒ 4. å¤„ç†ç½‘ç»œæ•…éšœ")
    network_scenario = OpsScenarioGenerator.generate_network_outage_scenario()
    
    print(f"äº‹ä»¶: {network_scenario['alert']['message']}")
    print(f"ä¸¢åŒ…ç‡: {network_scenario['alert']['metrics']['packet_loss']:.1%}")
    print(f"å»¶è¿Ÿ: {network_scenario['alert']['metrics']['latency']}ms")
    
    # ç½‘ç»œæ™ºèƒ½ä½“å¤„ç†
    network_agent = agents['network_specialist']
    network_result = await network_agent.process_alert(network_scenario['alert'])
    
    print(f"\nğŸ”— ç½‘ç»œæ™ºèƒ½ä½“å¤„ç†ç»“æœ: {network_result['status']}")
    
    # 5. æ€§èƒ½é—®é¢˜åœºæ™¯
    print("\nâš¡ 5. å¤„ç†æ€§èƒ½é—®é¢˜")
    memory_scenario = OpsScenarioGenerator.generate_memory_leak_scenario()
    
    print(f"äº‹ä»¶: {memory_scenario['alert']['message']}")
    print(f"å†…å­˜ä½¿ç”¨ç‡: {memory_scenario['alert']['metrics']['memory_usage']:.1%}")
    print(f"å †å¤§å°: {memory_scenario['alert']['metrics']['heap_size'] / 1000000000:.1f}GB")
    
    # æ€§èƒ½æ™ºèƒ½ä½“å¤„ç†
    performance_agent = agents['performance_specialist']
    performance_result = await performance_agent.process_alert(memory_scenario['alert'])
    
    print(f"\nğŸš€ æ€§èƒ½æ™ºèƒ½ä½“å¤„ç†ç»“æœ: {performance_result['status']}")
    
    # 6. ç³»ç»ŸçŠ¶æ€æ±‡æ€»
    print("\nğŸ“Š 6. ç³»ç»ŸçŠ¶æ€æ±‡æ€»")
    system_status = manager.get_system_status()
    print(f"æ€»æ™ºèƒ½ä½“æ•°: {system_status['total_agents']}")
    print(f"æ´»è·ƒæ™ºèƒ½ä½“æ•°: {system_status['active_agents']}")
    
    for agent_info in system_status['agent_list']:
        agent_id = agent_info['agent_id']
        status = agent_info['status']
        print(f"   {agent_id}: {status['current_state']} ({status['workflow_status']})")
    
    return manager


async def demo_learning_and_optimization():
    """æ¼”ç¤ºå­¦ä¹ å’Œä¼˜åŒ–åŠŸèƒ½"""
    print("\nğŸ§  å­¦ä¹ å’Œä¼˜åŒ–åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ”¯æŒå­¦ä¹ çš„æ™ºèƒ½ä½“
    print("\nğŸ“‹ 1. åˆ›å»ºæ”¯æŒå­¦ä¹ çš„æ™ºèƒ½ä½“")
    config = AgentConfig(
        agent_id="learning_agent",
        agent_type="adaptive",
        specialization="continuous_learning",
        enable_learning=True,
        enable_reporting=True
    )
    
    agent = IntelligentOpsAgent(config)
    print(f"âœ… å­¦ä¹ æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ: {config.agent_id}")
    
    # 2. å¤„ç†å¤šä¸ªåœºæ™¯ä»¥ç§¯ç´¯ç»éªŒ
    print("\nğŸ”„ 2. å¤„ç†å¤šä¸ªåœºæ™¯ä»¥ç§¯ç´¯ç»éªŒ")
    scenarios = [
        OpsScenarioGenerator.generate_cpu_spike_scenario(),
        OpsScenarioGenerator.generate_memory_leak_scenario(),
        OpsScenarioGenerator.generate_network_outage_scenario()
    ]
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"\n   åœºæ™¯ {i}: {scenario['alert']['message']}")
        result = await agent.process_alert(scenario['alert'])
        print(f"   å¤„ç†ç»“æœ: {result['status']}")
    
    # 3. æ¨¡æ‹Ÿåé¦ˆæ•°æ®
    print("\nğŸ“ 3. æä¾›åé¦ˆæ•°æ®")
    feedback_data = {
        "user_satisfaction": 0.85,
        "resolution_effectiveness": 0.90,
        "false_positive_rate": 0.05,
        "automation_accuracy": 0.88,
        "response_time_satisfaction": 0.92
    }
    
    learning_result = await agent.learn_from_feedback(feedback_data)
    print(f"å­¦ä¹ ç»“æœ: {learning_result['status']}")
    
    if learning_result['status'] == 'success':
        update_info = learning_result['learning_update']
        print(f"   å¤„ç†åé¦ˆç‚¹: {update_info['data_points_added']}")
        print(f"   æ€»å­¦ä¹ æ•°æ®: {update_info['total_learning_data']}")
    
    # 4. æ˜¾ç¤ºå­¦ä¹ åçš„æ€§èƒ½æŒ‡æ ‡
    print("\nğŸ“Š 4. å­¦ä¹ åçš„æ€§èƒ½æŒ‡æ ‡")
    metrics = agent.get_performance_metrics()
    print(f"å¤„ç†äº‹ä»¶æ•°: {metrics['incidents_processed']}")
    print(f"å­¦ä¹ æ•°æ®ç‚¹: {metrics['learning_data_points']}")
    print(f"å½“å‰æ€§èƒ½: {json.dumps(metrics['current_performance'], indent=2)}")
    
    return agent


async def demo_advanced_diagnostics():
    """æ¼”ç¤ºé«˜çº§è¯Šæ–­åŠŸèƒ½"""
    print("\nğŸ” é«˜çº§è¯Šæ–­åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    
    # 1. åˆ›å»ºè¯Šæ–­ä¸“å®¶æ™ºèƒ½ä½“
    print("\nğŸ“‹ 1. åˆ›å»ºè¯Šæ–­ä¸“å®¶æ™ºèƒ½ä½“")
    config = AgentConfig(
        agent_id="diagnostic_expert",
        agent_type="diagnostic",
        specialization="root_cause_analysis",
        enable_learning=True,
        enable_reporting=True
    )
    
    agent = IntelligentOpsAgent(config)
    print(f"âœ… è¯Šæ–­ä¸“å®¶åˆ›å»ºå®Œæˆ: {config.agent_id}")
    
    # 2. æä¾›ç—‡çŠ¶è¿›è¡Œè¯Šæ–­
    print("\nğŸ” 2. åŸºäºç—‡çŠ¶è¿›è¡Œè¯Šæ–­")
    symptoms = [
        "API response time increased by 300%",
        "Database connection pool exhausted",
        "Memory usage gradually increasing",
        "CPU usage spikes during peak hours",
        "Error rate increased from 0.1% to 5%"
    ]
    
    context = {
        "system_metrics": {
            "cpu_usage": 0.85,
            "memory_usage": 0.90,
            "disk_io": 0.70,
            "network_latency": 250
        },
        "log_entries": [
            "2024-01-01 12:00:00 ERROR: Connection timeout",
            "2024-01-01 12:00:05 WARN: Memory pressure detected",
            "2024-01-01 12:00:10 ERROR: Database connection failed"
        ],
        "topology_info": {
            "services": ["web", "api", "database", "cache"],
            "dependencies": {
                "web": ["api"],
                "api": ["database", "cache"],
                "database": [],
                "cache": []
            }
        }
    }
    
    print("ç—‡çŠ¶åˆ—è¡¨:")
    for i, symptom in enumerate(symptoms, 1):
        print(f"   {i}. {symptom}")
    
    diagnosis_result = await agent.diagnose_issue(symptoms, context)
    print(f"\nğŸ”¬ è¯Šæ–­ç»“æœ: {diagnosis_result['status']}")
    
    if diagnosis_result['status'] == 'success':
        diagnosis = diagnosis_result['diagnosis']
        print(f"   æ ¹å› : {diagnosis['root_cause']}")
        print(f"   ç½®ä¿¡åº¦: {diagnosis['confidence_score']:.2f}")
        print(f"   å½±å“è¯„ä¼°: {diagnosis['impact_assessment']}")
        print(f"   å—å½±å“ç»„ä»¶: {', '.join(diagnosis['affected_components'])}")
        print(f"   æ¢å¤æ—¶é—´ä¼°è®¡: {diagnosis['recovery_estimate']}")
    
    # 3. åŸºäºè¯Šæ–­ç»“æœç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’
    print("\nğŸ“‹ 3. ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’")
    if diagnosis_result['status'] == 'success':
        plan_result = await agent.plan_actions(
            diagnosis_result['diagnosis'], 
            context
        )
        
        print(f"è¡ŒåŠ¨è®¡åˆ’çŠ¶æ€: {plan_result['status']}")
        
        if plan_result['status'] == 'success':
            plan = plan_result['action_plan']
            print(f"   è®¡åˆ’ID: {plan['plan_id']}")
            print(f"   ä¼˜å…ˆçº§: {plan['priority']}")
            print(f"   é¢„ä¼°æ—¶é—´: {plan['estimated_duration']}åˆ†é’Ÿ")
            print(f"   éœ€è¦å®¡æ‰¹: {plan['approval_required']}")
            print(f"   æ­¥éª¤æ•°é‡: {len(plan['steps'])}")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªæ­¥éª¤
            print("   ä¸»è¦æ­¥éª¤:")
            for i, step in enumerate(plan['steps'][:3], 1):
                print(f"     {i}. {step['description']}")
    
    return agent


async def main():
    """ä¸»è¦æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ æ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“å®Œæ•´åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    # å•ä¸ªæ™ºèƒ½ä½“æ¼”ç¤º
    single_agent = await demo_single_agent_ops()
    
    # å¤šæ™ºèƒ½ä½“åä½œæ¼”ç¤º
    multi_agent_manager = await demo_multi_agent_collaboration()
    
    # å­¦ä¹ å’Œä¼˜åŒ–æ¼”ç¤º
    learning_agent = await demo_learning_and_optimization()
    
    # é«˜çº§è¯Šæ–­æ¼”ç¤º
    diagnostic_agent = await demo_advanced_diagnostics()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æ¼”ç¤ºæ€»ç»“")
    print("=" * 60)
    
    print(f"âœ… å•ä¸ªæ™ºèƒ½ä½“æ¼”ç¤º: å®Œæˆ")
    print(f"âœ… å¤šæ™ºèƒ½ä½“åä½œæ¼”ç¤º: å®Œæˆ")
    print(f"âœ… å­¦ä¹ å’Œä¼˜åŒ–æ¼”ç¤º: å®Œæˆ")
    print(f"âœ… é«˜çº§è¯Šæ–­æ¼”ç¤º: å®Œæˆ")
    
    print("\nğŸ’¡ å…³é”®ç‰¹æ€§æ¼”ç¤º:")
    print("   ğŸ”„ LangGraph å·¥ä½œæµç¼–æ’")
    print("   ğŸ§  DSPy æ¨¡å—åŒ–æ¨ç†")
    print("   ğŸ¤– å¤šæ™ºèƒ½ä½“åä½œ")
    print("   ğŸ“Š æ™ºèƒ½è¯Šæ–­åˆ†æ")
    print("   ğŸ“‹ è‡ªåŠ¨åŒ–è¡ŒåŠ¨è§„åˆ’")
    print("   ğŸ“ˆ æŒç»­å­¦ä¹ ä¼˜åŒ–")
    print("   ğŸ“„ æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆ")
    
    print("\nğŸ‰ æ™ºèƒ½è¿ç»´æ™ºèƒ½ä½“å®Œæ•´åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())